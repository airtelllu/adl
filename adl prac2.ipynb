{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3d997f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 6s 8ms/step - loss: 1.1373 - accuracy: 0.8809 - val_loss: 0.6308 - val_accuracy: 0.9097\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5684 - accuracy: 0.9180 - val_loss: 0.5044 - val_accuracy: 0.9273\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4994 - accuracy: 0.9265 - val_loss: 0.4690 - val_accuracy: 0.9315\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.4616 - accuracy: 0.9335 - val_loss: 0.4341 - val_accuracy: 0.9417\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.4353 - accuracy: 0.9381 - val_loss: 0.4168 - val_accuracy: 0.9419\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4100 - accuracy: 0.9422 - val_loss: 0.3874 - val_accuracy: 0.9486\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3906 - accuracy: 0.9447 - val_loss: 0.3730 - val_accuracy: 0.9487\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3769 - accuracy: 0.9478 - val_loss: 0.3540 - val_accuracy: 0.9532\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3620 - accuracy: 0.9497 - val_loss: 0.3441 - val_accuracy: 0.9543\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3501 - accuracy: 0.9513 - val_loss: 0.3426 - val_accuracy: 0.9485\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the data\n",
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "train_data = train_data.reshape((60000, 784)) / 255.0\n",
    "test_data = test_data.reshape((10000, 784)) / 255.0\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,),\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, train_labels, epochs=10, batch_size=128, validation_data=(test_data, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531604e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 5s 8ms/step - loss: 1.1407 - accuracy: 0.8831 - val_loss: 0.6073 - val_accuracy: 0.9152\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5627 - accuracy: 0.9196 - val_loss: 0.5240 - val_accuracy: 0.9210\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4944 - accuracy: 0.9288 - val_loss: 0.4522 - val_accuracy: 0.9383\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4555 - accuracy: 0.9352 - val_loss: 0.4290 - val_accuracy: 0.9399\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4277 - accuracy: 0.9396 - val_loss: 0.4033 - val_accuracy: 0.9427\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4054 - accuracy: 0.9433 - val_loss: 0.3842 - val_accuracy: 0.9474\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.9474 - val_loss: 0.3651 - val_accuracy: 0.9500\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3697 - accuracy: 0.9490 - val_loss: 0.3669 - val_accuracy: 0.9497\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.3538 - accuracy: 0.9510 - val_loss: 0.3386 - val_accuracy: 0.9543\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3421 - accuracy: 0.9528 - val_loss: 0.3384 - val_accuracy: 0.9535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This code trains the model using the fit() function.The training data and␣labels are passed in as arguments,\\nalong with the number of epochs to train for, the batch size to use, and the validation data to use for\\nmonitoring model performance during training. The fit() function returns a history object that contains information\\nabout the training process, such as the loss and accuracy at each epoch.\\nThe purpose of this program is to demonstrate how to implement a neural network model for image classification\\nusing TensorFlow/Keras. The model uses regularization techniques to prevent overfitting and achieves high accuracy\\non the MNIST dataset.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf  # Import TensorFlow library\n",
    "\n",
    "# Load the data\n",
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.mnist.load_data()  # Load MNIST dataset\n",
    "\n",
    "'''Loads the MNIST dataset using the load_data() function provided by Keras, a high-level API of TensorFlow.\n",
    "The MNIST dataset contains 70,000 images of handwritten digits that are split into 60,000 training images\n",
    "and 10,000 testing images.'''\n",
    "\n",
    "# Preprocess the data\n",
    "train_data = train_data.reshape((60000, 784)) / 255.0  # Reshape and normalize training data\n",
    "test_data = test_data.reshape((10000, 784)) / 255.0  # Reshape and normalize testing data\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)  # Convert training labels to one-hot encoding\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)  # Convert testing labels to one-hot encoding\n",
    "\n",
    "'''Preprocess the data. The images are first reshaped from a 3D array (28x28 pixels) to a 2D array (784 pixels).\n",
    "Then, the pixel values are normalized to be between 0 and 1 by dividing by 255.\n",
    "The labels are converted to one-hot encoding format using the to_categorical() function provided by Keras.\n",
    "This is done to make it easier for the model to classify the images into 10 different classes (one for each digit).'''\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Define sequential model\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,), kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    # Add a fully connected layer with 128 units, ReLU activation, and L2 regularization\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    # Add another fully connected layer with 64 units, ReLU activation, and L2 regularization\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # Add a final output layer with 10 units (one for each class), softmax activation\n",
    "])\n",
    "\n",
    "'''This code defines the architecture of the neural network model.\n",
    "The Sequential() function is used to create a sequential model, meaning that the layers are added in sequence.\n",
    "Three fully connected layers are defined using the Dense() function.\n",
    "The first layer has 128 units, ReLU activation, and L2 regularization with a regularization parameter of 0.01.\n",
    "The second layer has 64 units, ReLU activation, and L2 regularization with a regularization parameter of 0.01.\n",
    "The third and final layer has 10 units, softmax activation, and is used for the classification task.'''\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # Use Adam optimizer with learning rate 0.001\n",
    "              loss='categorical_crossentropy',  # Use categorical cross-entropy loss function\n",
    "              metrics=['accuracy'])  # Monitor accuracy during training\n",
    "\n",
    "'''This code compiles the model. The compile() function configures the model for training by specifying the optimizer,\n",
    "loss function, and metrics to monitor during training.\n",
    "In this case, the Adam optimizer is used with a learning rate of 0.001, categorical cross-entropy is used as the loss function,\n",
    "and accuracy is monitored during training.'''\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, train_labels, epochs=10, batch_size=128, validation_data=(test_data, test_labels))\n",
    "\n",
    "'''This code trains the model using the fit() function.The training data and␣labels are passed in as arguments,\n",
    "along with the number of epochs to train for, the batch size to use, and the validation data to use for\n",
    "monitoring model performance during training. The fit() function returns a history object that contains information\n",
    "about the training process, such as the loss and accuracy at each epoch.\n",
    "The purpose of this program is to demonstrate how to implement a neural network model for image classification\n",
    "using TensorFlow/Keras. The model uses regularization techniques to prevent overfitting and achieves high accuracy\n",
    "on the MNIST dataset.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b22570",
   "metadata": {},
   "outputs": [],
   "source": [
    "Write a Program to implement regularization to prevent the model from overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acca6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "Theory: Regularization is a technique which makes slight modifications to the learning algorithm such\n",
    "that the model generalizes better. This in turn improves the model’s performance on the unseen data as\n",
    "well. L1 and L2 are the most common types of regularization. These update the general cost function by\n",
    "adding another term known as the regularization term.\n",
    "Cost function = Loss (say, binary cross entropy) + Regularization term\n",
    "Due to the addition of this regularization term, the values of weight matrices decrease because it assumes\n",
    "that a neural network with smaller weight matrices leads to simpler models. Therefore, it will also reduce\n",
    "overfitting to quite an extent. However, this regularization term differs in L1 and L2.\n",
    "In L2, we have:\n",
    "Here, lambda is the regularization parameter. It is the hyperparameter whose value is optimized for better\n",
    "results. L2 regularization is also known as weight decay as it forces the weights to decay towards zero\n",
    "(but not exactly zero).\n",
    "In L1, we have:\n",
    "In this, we penalize the absolute value of the weights. Unlike L2, the weights may be reduced to zero\n",
    "here. Hence, it is very useful when we are trying to compress our model. Otherwise, we usually prefer\n",
    "L2 over it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
